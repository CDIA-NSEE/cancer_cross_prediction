{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOyW4oSD0pkzoNKo65QA9W8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","from sklearn.impute import KNNImputer\n","\n","# Graphs\n","import matplotlib.pyplot as plt\n","\n","# Preprocessing\n","from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, MaxAbsScaler, QuantileTransformer, OneHotEncoder\n","from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n","from imblearn.over_sampling import SMOTE\n","\n","# Metrics\n","from sklearn.metrics import roc_curve, roc_auc_score, auc, ConfusionMatrixDisplay, classification_report\n","from sklearn import tree\n","\n","# SHAP values\n","import shap"],"metadata":{"id":"X-3C0xa5uXNH"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Rt7wW0buHod"},"outputs":[],"source":["def data_prep(df, topogrup):\n","    \"\"\"\n","    Prepara o conjunto de dados para análise, aplicando filtros e transformações necessárias.\n","\n","    Parâmetros:\n","    -----------\n","    df : pandas.DataFrame\n","        O conjunto de dados que será preparado.\n","    topogrup : list\n","        Lista com os códigos do grupo da topografia para serem selecionados.\n","\n","    Retorno:\n","    --------\n","    pandas.DataFrame\n","        O conjunto de dados após as transformações.\n","\n","    \"\"\"\n","\n","    df_aux = df.copy()\n","\n","    # TOPOGRUP\n","    df_aux = df_aux[df_aux.TOPOGRUP.isin(topogrup)]\n","\n","    # IDADE > 19\n","    df_aux = df_aux[df_aux.IDADE > 19]\n","\n","    # Somente residentes do estado de SP\n","    df_aux = df_aux[df_aux.UFRESID == 'SP']\n","\n","    # ECGRUP sem 0, X e Y\n","    df_aux = df_aux[~df_aux.ECGRUP.isin(['0','X','Y'])]\n","\n","    # ANODIAG até 2019 e em categorias de 5 em 5 anos\n","    df_aux = df_aux[df_aux.ANODIAG < 2020]\n","    # df_aux.ANODIAG = [0 if x < 2005 else 1 if x < 2010 else 2 if x < 2015 else 3 for x in df_aux.ANODIAG]\n","\n","    # Somente com confirmação microscópica\n","    df_aux = df_aux[df_aux.BASEDIAG == 3]\n","\n","    # Somente MORFO 81403\n","    # df_aux = df_aux[df_aux.MORFO == 81403]\n","\n","    # Tratamento das colunas com datas\n","    list_datas = ['DTCONSULT', 'DTDIAG', 'DTTRAT', 'DTULTINFO']\n","\n","    for col_data in list_datas:\n","        df_aux[col_data] = pd.to_datetime(df_aux[col_data])\n","\n","    df_aux['CONSDIAG'] = (df_aux.DTDIAG - df_aux.DTCONSULT).dt.days\n","    df_aux['DIAGTRAT'] = (df_aux.DTTRAT - df_aux.DTDIAG).dt.days\n","    df_aux['TRATCONS'] = (df_aux.DTTRAT - df_aux.DTCONSULT).dt.days\n","    df_aux['ULTIDIAG'] = (df_aux.DTULTINFO - df_aux.DTDIAG).dt.days\n","    df_aux[['DIAGTRAT', 'TRATCONS']] = df_aux[['DIAGTRAT', 'TRATCONS']].fillna(-1)\n","\n","    df_aux.CONSDIAG = [0 if consdiag <= 30 else 1 if consdiag <= 60 else 2 for consdiag in df_aux.CONSDIAG]\n","    df_aux.TRATCONS = [99 if tratcons < 0 else 0 if tratcons <= 60 else 1 if tratcons <= 90 else 2 for tratcons in df_aux.TRATCONS]\n","    df_aux.DIAGTRAT = [99 if diagtrat < 0 else 0 if diagtrat <= 60 else 1 if diagtrat <= 90 else 2 for diagtrat in df_aux.DIAGTRAT]\n","\n","    # Input da ESCOLARI usando ECGRUP, IDADE e SEXO\n","    cols_input = ['ESCOLARI', 'IDADE', 'ECGRUP', 'SEXO']\n","\n","    df_esc = df_aux[cols_input].copy()\n","    df_esc.loc[df_esc.ESCOLARI == 9, 'ESCOLARI'] = np.nan\n","    df_esc.loc[df_esc.ECGRUP == 'I', 'ECGRUP'] = 1\n","    df_esc.loc[df_esc.ECGRUP == 'II', 'ECGRUP'] = 2\n","    df_esc.loc[df_esc.ECGRUP == 'III', 'ECGRUP'] = 3\n","    df_esc.loc[df_esc.ECGRUP == 'IV', 'ECGRUP'] = 4\n","\n","    X = df_esc.values\n","    imputer = KNNImputer(n_neighbors=5, weights='distance')\n","    df_aux['ESCOLARI_preench'] = imputer.fit_transform(X)[:,0].round()\n","\n","    # Variável para pessoas que fazem tratamento na mesma cidade (0 = Não, 1 = Sim)\n","    df_aux['IBGE_idem_IBGEATEN'] = 0\n","    df_aux.loc[df_aux.IBGE == df_aux.IBGEATEN, 'IBGE_idem_IBGEATEN'] = 1\n","\n","    # Variável para presença de recidiva (0 = Não, 1 = Sim)\n","    df_aux['presenca_rec'] = [0 if rec == 1 else 1 for rec in df_aux.RECNENHUM]\n","    df_aux.loc[(df_aux.presenca_rec == 0) & (df_aux.DTRECIDIVA.notnull()), 'presenca_rec'] = 1\n","\n","    # Somente o número da DRS\n","    DRS_expand = df_aux.DRS.str.split(' ', expand=True)\n","    df_aux['DRS'] = DRS_expand[1]\n","\n","    # Retirada das colunas que não serão usadas\n","    cols = df_aux.columns\n","    drop_cols = ['ESCOLARI', 'UFNASC', 'UFRESID', 'CIDADE', 'DTCONSULT', 'CLINICA',\n","                 'DTDIAG', 'BASEDIAG', 'DESCTOPO', 'MORFO', 'DESCMORFO', 'ECGRUP',\n","                 'T', 'N', 'M', 'PT', 'PN', 'PM', 'S', 'G', 'LOCALTNM', 'IDMITOTIC',\n","                 'PSA', 'GLEASON', 'OUTRACLA', 'META01', 'META02', 'META03',\n","                 'META04', 'DTTRAT', 'NAOTRAT', 'TRATAMENTO', 'TRATFANTES',\n","                 'TRATFAPOS', 'NENHUMANT', 'CIRURANT', 'RADIOANT', 'QUIMIOANT',\n","                 'HORMOANT', 'TMOANT', 'IMUNOANT', 'OUTROANT', 'NENHUMAPOS',\n","                 'CIRURAPOS', 'RADIOAPOS', 'QUIMIOAPOS', 'HORMOAPOS', 'TMOAPOS',\n","                 'IMUNOAPOS', 'OUTROAPOS', 'DTULTINFO', 'CICI', 'CICIGRUP',\n","                 'CICISUBGRU', 'FAIXAETAR', 'LATERALI', 'INSTORIG', 'PERDASEG',\n","                 'ERRO', 'DTRECIDIVA', 'RECNENHUM', 'RECLOCAL', 'RECREGIO',\n","                 'RECDIST', 'REC01', 'REC02', 'REC03', 'REC04', 'CIDO', 'DSCCIDO',\n","                 'HABILIT', 'HABIT11', 'HABILIT1', 'CIDADEH']\n","\n","    cols = cols.drop(drop_cols)\n","\n","    return df_aux[cols]\n","\n","#######################################################################################\n","\n","def get_labels(df):\n","    \"\"\"\n","    Cria novas colunas para indicar se o paciente morreu, se morreu devido a câncer e se está vivo após 1, 3 e 5 anos\n","    a partir do diagnóstico.\n","\n","    Parâmetros:\n","    -----------\n","    df : pandas.DataFrame\n","        DataFrame contendo os dados dos pacientes.\n","\n","    Retorno:\n","    --------\n","    pandas.DataFrame\n","        DataFrame com as novas colunas adicionadas.\n","\n","    \"\"\"\n","\n","    df_aux = df.copy()\n","\n","    df_aux['obito_geral'] = 0\n","    # df_aux['obito_cancer'] = 0\n","\n","    df_aux['sobrevida_ano1'] = 0\n","    df_aux['sobrevida_ano3'] = 0\n","    df_aux['sobrevida_ano5'] = 0\n","\n","    df_aux.loc[df_aux.ULTINFO > 2, 'obito_geral'] = 1\n","\n","    # df_aux.loc[df_aux.ULTINFO == 3, 'obito_cancer'] = 1\n","\n","    df_aux.loc[df_aux.ULTIDIAG > 365, 'sobrevida_ano1'] = 1\n","    df_aux.loc[df_aux.ULTIDIAG > 3*365, 'sobrevida_ano3'] = 1\n","    df_aux.loc[df_aux.ULTIDIAG > 5*365, 'sobrevida_ano5'] = 1\n","\n","    # df_ano1 = df_aux[~((df_aux.obito_geral == 0) & (df_aux.sobrevida_ano1 == 0))].reset_index(drop=True)\n","\n","    drop = ['ULTINFO', 'ULTIDIAG']#'obito_geral']\n","\n","    return df_aux.drop(columns=drop)\n","\n","#######################################################################################\n","\n","def get_train_test(df, drop_cols, label, test_size=0.25, random_state=0):\n","    \"\"\"\n","    Divide o dataframe em dados de treino e teste, de acordo com uma variável target e uma lista de colunas a serem\n","    excluídas. Retorna quatro dataframes: X_train, X_test, y_train, y_test.\n","\n","    Parâmetros:\n","    -----------\n","    df : DataFrame\n","        Dataframe que será dividido em treino e teste.\n","    drop_cols : list\n","        Lista de colunas a serem excluídas do dataframe.\n","    label : str\n","        Nome da coluna que é a variável target.\n","    test_size : float, opcional (padrão=0.25)\n","        Tamanho da fração dos dados que será utilizada para teste.\n","    random_state : int, opcional (padrão=0)\n","        Semente para a geração de números aleatórios.\n","\n","    Retorno:\n","    --------\n","    X_train : DataFrame\n","        Dataframe de treino com as features.\n","    X_test : DataFrame\n","        Dataframe de teste com as features.\n","    y_train : DataFrame\n","        Dataframe de treino com a variável target.\n","    y_test : DataFrame\n","        Dataframe de teste com a variável target.\n","\n","    \"\"\"\n","\n","    df_aux = df.copy()\n","\n","    cols = df_aux.columns.drop(drop_cols)\n","    lb = df_aux[label].copy()\n","    cols = cols.drop(label)\n","    feat = df_aux[cols]\n","\n","    X_train, X_test, y_train, y_test = train_test_split(feat, lb,\n","                                                        test_size=test_size,\n","                                                        random_state=random_state,\n","                                                        stratify=lb)\n","\n","    return X_train, X_test, y_train, y_test\n","\n","#######################################################################################\n","\n","def train_preprocessing(df, ohe_encoder=None, normalizer='StandardScaler'):\n","    \"\"\"\n","    Realiza o pré-processamento do conjunto de treino.\n","\n","    Parâmetros:\n","    -----------\n","    df : pandas.DataFrame\n","        O conjunto de dados a ser pré-processado.\n","    ohe_encoder : lista, opcional\n","        Lista com as colunas para realizar o One Hot Encoder, se None, todas as colunas serão codificadas com o Label Encoder.\n","    normalizer : str, opcional\n","        Tipo de normalização a ser usada para escalonamento das variáveis (padrão é 'StandardScaler').\n","\n","    Retorno:\n","    --------\n","    df_aux : pandas.DataFrame\n","        O conjunto de dados pré-processado.\n","    enc : dict\n","        Dicionário de codificadores de rótulos, contendo um codificador para cada variável categórica.\n","    norm : objeto\n","        Normalizador de dados utilizado para escalonamento das variáveis.\n","    feat_cols : lista\n","        Lista com o nome das colunas das variáveis do modelo.\n","\n","    \"\"\"\n","    df_aux = df.copy()\n","\n","    enc = dict()\n","    if ohe_encoder != None:\n","        for col in ohe_encoder:\n","            enc[col] = OneHotEncoder(handle_unknown='ignore', drop='first')\n","            ohe_results = enc[col].fit_transform(df_aux[[col]])\n","            df1 = pd.DataFrame(ohe_results.toarray(),\n","                               columns=enc[col].get_feature_names_out(),\n","                               index=df_aux[col].index)\n","            df_aux = df_aux.merge(df1, how='left', left_index=True, right_index=True)\n","\n","        df_aux.drop(columns=ohe_encoder, inplace=True)\n","\n","    list_categorical = df_aux.select_dtypes(include='object').columns\n","    for col in list_categorical:\n","        enc[col] = LabelEncoder()\n","        df_aux[col] = enc[col].fit_transform(df_aux[col])\n","\n","    feat_cols = df_aux.columns\n","\n","    if normalizer == 'StandardScaler':\n","        norm = StandardScaler()\n","    elif normalizer == 'MinMaxScaler':\n","        norm = MinMaxScaler((0, 1))\n","    elif normalizer == 'MaxAbsScaler':\n","        norm = MaxAbsScaler()\n","    elif normalizer == 'QuantileTransformer':\n","        norm = QuantileTransformer(output_distribution='normal')\n","\n","    df_aux = norm.fit_transform(df_aux)\n","\n","    return df_aux, enc, norm, feat_cols\n","\n","#######################################################################################\n","\n","def test_preprocessing(df, enc, norm, ohe_encoder=None):\n","    \"\"\"\n","    Realiza o pré-processamento do conjunto de teste.\n","\n","    Parâmetros:\n","    -----------\n","    df : pandas DataFrame\n","        O conjunto de dados a ser pré-processado.\n","    enc : dict\n","        Dicionário contendo os objetos encoders utilizados para pré-processar os dados de treino.\n","    norm : objeto de normalização\n","        Objeto de normalização utilizado para pré-processar os dados de treino.\n","    ohe_encoder : lista, padrão None\n","        Lista com as colunas para realizar o One Hot Encoder, se None, todas as colunas serão codificadas com o Label Encoder.\n","\n","    Retorno:\n","    --------\n","    pandas DataFrame\n","        O conjunto de dados pré-processado.\n","\n","    \"\"\"\n","\n","    df_aux = df.copy()\n","\n","    if ohe_encoder != None:\n","        for col in ohe_encoder:\n","            ohe_results = enc[col].transform(df_aux[[col]])\n","            df1 = pd.DataFrame(ohe_results.toarray(),\n","                               columns=enc[col].get_feature_names_out(),\n","                               index=df_aux[col].index)\n","            df_aux = df_aux.merge(df1, how='left', left_index=True, right_index=True)\n","\n","        df_aux.drop(columns=ohe_encoder, inplace=True)\n","\n","    list_categorical = df_aux.select_dtypes(include='object').columns\n","    for col in list_categorical:\n","        df_aux.loc[~df_aux[col].isin(enc[col].classes_), col] = -1\n","        df_aux.loc[df_aux[col].isin(enc[col].classes_), col] = enc[col].transform(df_aux[col][df_aux[col].isin(enc[col].classes_)])\n","\n","    df_aux = norm.transform(df_aux)\n","\n","    return df_aux\n","\n","#######################################################################################\n","\n","def preprocessing(df, cols_drop, label, test_size=0.25, ohe_encoder=None,\n","                  norm_name='StandardScaler', return_enc_norm=False,\n","                  balance_data=False, random_state=0):\n","    \"\"\"\n","    Realiza o pré-processamento dos dados de treino e teste.\n","\n","    Parâmetros:\n","    -----------\n","    df : pandas DataFrame\n","        O DataFrame contendo as features e o label.\n","    cols_drop : lista\n","        Lista com o nome das colunas que devem ser removidas do DataFrame.\n","    label : str\n","        O nome da coluna do label.\n","    test_size : float, padrão 0.25\n","        Tamanho da porcentagem dos dados que serão usados para teste.\n","    ohe_encoder : lista, padrão None\n","        Lista com as colunas para realizar o One Hot Encoder, se None, todas as colunas serão codificadas com o Label Encoder.\n","    norm_name : str, padrão 'StandardScaler'\n","        Nome do normalizador a ser usado, podendo ser 'StandardScaler', 'MinMaxScaler', 'MaxAbsScaler' ou 'QuantileTransformer'.\n","    return_enc_norm : bool, padrão False\n","        Se True, retorna os objetos enc e norm que foram usados no pré-processamento dos dados.\n","    balance_data : bool, padrão False\n","        Se True, realiza balanceamento dos dados usando a técnica SMOTE.\n","    random_state : int, padrão 0\n","        Semente aleatória para reprodutibilidade.\n","\n","    Retornos:\n","    ---------\n","    X_train_ : numpy ndarray\n","        Matriz de features de treino pré-processada.\n","    X_test_ : numpy ndarray\n","        Matriz de features de teste pré-processada.\n","    y_train_ : numpy ndarray\n","        Array da variável alvo de treino.\n","    y_test : numpy ndarray\n","        Array da variável alvo de teste.\n","    feat_cols : lista\n","        Lista com o nome das colunas das features após o pré-processamento.\n","    enc : dict\n","        Dicionário contendo os objetos LabelEncoder ou OneHotEncoder de cada coluna categórica.\n","        (somente se return_enc_norm for True)\n","    norm : objeto normalizador\n","        Objeto normalizador de cada coluna numérica.\n","        (somente se return_enc_norm for True)\n","\n","    \"\"\"\n","    df_aux = df.copy()\n","\n","    # Train Test split\n","    X_train, X_test, y_train, y_test = get_train_test(df_aux, cols_drop, label,\n","                                                      test_size,\n","                                                      random_state=random_state)\n","\n","    # Preprocessing\n","    X_train_enc, enc, norm, feat_cols = train_preprocessing(X_train, ohe_encoder=ohe_encoder,\n","                                                            normalizer=norm_name)\n","    X_test_ = test_preprocessing(X_test, enc, norm, ohe_encoder=ohe_encoder)\n","\n","    # Balancing\n","    if balance_data:\n","        X_train_, y_train_ = SMOTE(random_state=random_state).fit_resample(X_train_enc, y_train)\n","\n","    else:\n","        X_train_, y_train_ = X_train_enc, y_train\n","\n","    print(f'X_train = {X_train_.shape}, X_test = {X_test_.shape}')\n","    print(f'y_train = {y_train_.shape}, y_test = {y_test.shape}')\n","\n","    if return_enc_norm:\n","        return X_train_, X_test_, y_train_, y_test, feat_cols, enc, norm\n","    else:\n","        return X_train_, X_test_, y_train_, y_test, feat_cols\n","\n","#######################################################################################\n","\n","def show_tree(model, feat_cols, max_depth=3, estimator=0):\n","    \"\"\"\n","    Plota a árvore de decisão de um modelo RandomForestClassifier.\n","\n","    Parâmetros:\n","    -----------\n","    model : RandomForestClassifier\n","        Modelo treinado do tipo RandomForestClassifier.\n","    feat_cols : array-like\n","        Lista ou array com os nomes das features utilizadas no treinamento.\n","    max_depth : int, opcional\n","        A profundidade máxima da árvore a ser exibida. O valor padrão é 3.\n","    estimator : int, opcional\n","        O índice do estimador a ser exibido. O valor padrão é 0.\n","\n","    Retorno:\n","    --------\n","    None\n","\n","    \"\"\"\n","    plt.figure(figsize = (22, 10))\n","    tree.plot_tree(model.estimators_[estimator],\n","                   feature_names=feat_cols,\n","                   filled=True,\n","                   max_depth=max_depth);\n","\n","#######################################################################################\n","\n","def plot_feat_importances(model, feat_cols, n=10):\n","    \"\"\"\n","    Plota o gráfico de barras com as n características mais importantes de um modelo.\n","\n","    Parâmetros:\n","    -----------\n","    model: objeto\n","        Objeto do modelo já treinado.\n","\n","    feat_cols: array-like\n","        Lista ou array contendo o nome das colunas das features.\n","\n","    n: int, default=10\n","        Número de features mais importantes a serem plotadas.\n","\n","    Retorno:\n","    --------\n","    None\n","\n","    \"\"\"\n","\n","    feat_import = pd.Series(model.feature_importances_, index=feat_cols)\n","    feat_import.nlargest(n).plot(kind='barh', figsize=(10, 8))\n","    plt.show()\n","\n","#######################################################################################\n","\n","def plot_roc_curve(model, X_train, X_test, y_train, y_test):\n","    \"\"\"\n","    Plota a curva ROC para o modelo especificado usando as previsões de probabilidade de treino e teste.\n","    AUC é calculado para as curvas de treino e teste e plotado no gráfico.\n","\n","    Parâmetros:\n","    -----------\n","    model : modelo de classificação\n","        Um modelo de classificação treinado com método `fit` e que tenha um método `predict_proba`.\n","    X_train : pandas DataFrame\n","        Dados de treino contendo as features.\n","    X_test : pandas DataFrame\n","        Dados de teste contendo as features.\n","    y_train : pandas Series\n","        Variável label correspondente aos dados de treino.\n","    y_test : pandas Series\n","        Variável label correspondente aos dados de teste.\n","\n","    Retorno:\n","    --------\n","    None\n","\n","    \"\"\"\n","    probas_train = model.predict_proba(X_train)[:, 1]\n","    probas_test = model.predict_proba(X_test)[:, 1]\n","\n","    fp_train, tp_train, _ = roc_curve(y_train, probas_train)\n","    fp_test, tp_test, _ = roc_curve(y_test, probas_test)\n","\n","    plt.figure(figsize=(10, 7))\n","    plt.plot(fp_train, tp_train, 'b', label=f'Train (AUC = {auc(fp_train, tp_train):.4f})')\n","    plt.plot(fp_test, tp_test, 'r', label=f'Test (AUC = {auc(fp_test, tp_test):.4f})')\n","    plt.plot(np.linspace(0, 1, 100),\n","             np.linspace(0, 1, 100),\n","             label='Baseline',\n","             linestyle='--',\n","             color='k')\n","    plt.xlabel('False Positives')\n","    plt.ylabel('True Positives')\n","    plt.grid(True)\n","    plt.legend()\n","    plt.show()\n","\n","#######################################################################################\n","\n","def plot_confusion_matrix(model, x, y, format='.4f', norm=True):\n","    \"\"\"\n","    Plota uma matriz de confusão normalizada e um relatório de classificação.\n","\n","    Parâmetros:\n","    -----------\n","    model : estimador\n","        Um modelo de classificação já treinado.\n","    x : array-like, shape (n_samples, n_features)\n","        Conjunto de teste com as features.\n","    y : array-like, shape (n_samples,)\n","        Conjunto de teste com o label.\n","    format : str, opcional (padrão='.3f')\n","        O formato a ser usado para os valores na matriz de confusão.\n","\n","    Retorno:\n","    --------\n","    None\n","\n","    \"\"\"\n","    with plt.rc_context({'font.size': 12, 'font.weight': 'bold'}):\n","        if norm:\n","            ConfusionMatrixDisplay.from_estimator(model, x, y, values_format=format,\n","                                                  cmap='binary', normalize='true')\n","        else:\n","            ConfusionMatrixDisplay.from_estimator(model, x, y, cmap='binary',\n","                                                  values_format='.1f')\n","        plt.show()\n","\n","    print(f'\\n{classification_report(y, model.predict(x), digits=4)}')\n","\n","#######################################################################################\n","\n","def plot_shap_values(model, x, features, max_display=10):\n","    \"\"\"\n","    Plota o gráfico de valores shapley para cada feature.\n","\n","    Parâmetros:\n","    -----------\n","    model: modelo treinado\n","        Modelo que será utilizado para calcular os valores shapley.\n","    x: pd.DataFrame\n","        Dados de entrada que serão utilizados para calcular os valores shapley.\n","    features: list\n","        Lista de strings com o nome das colunas das features.\n","    max_display: int, optional\n","        Número máximo de features a serem exibidas no gráfico. Padrão é 10.\n","\n","    Retorno:\n","    --------\n","    None\n","\n","    \"\"\"\n","    shap_values = shap.TreeExplainer(model).shap_values(x)\n","\n","    try:\n","        shap.summary_plot(shap_values[1], x,\n","                          feature_names=features,\n","                          max_display=max_display)\n","    except AssertionError:\n","        shap.summary_plot(shap_values, x,\n","                          feature_names=features,\n","                          max_display=max_display)\n","\n","#######################################################################################\n","\n","def roc_together(X, y, naive_bayes=None, random_forest=None, xgboost=None,\n","                 lightgbm=None):\n","    \"\"\"\n","    Plota a curva ROC para vários modelos.\n","\n","    Parâmetros:\n","    -----------\n","    X: array-like\n","        Array com os valores das features.\n","    y: array-like\n","        Array com os valores do target.\n","    naive_bayes: objeto da classe GaussianNB, opcional (padrão=None)\n","        Objeto do modelo Gaussian Naive Bayes.\n","    random_forest: objeto da classe RandomForestClassifier, opcional (padrão=None)\n","        Objeto do modelo Random Forest Classifier.\n","    xgboost: objeto da classe XGBClassifier, opcional (padrão=None)\n","        Objeto do modelo XGBoost Classifier.\n","    lightgbm: objeto da classe LGBMClassifier, opcional (padrão=None)\n","        Objeto do modelo LightGBM Classifier.\n","\n","    Retorno:\n","    --------\n","    None\n","\n","    \"\"\"\n","    plt.figure(figsize=(10, 7))\n","\n","    if naive_bayes != None:\n","        probas_nb = naive_bayes.predict_proba(X)[:, 1]\n","        fp_nb, tp_nb, _ = roc_curve(y, probas_nb)\n","        plt.plot(fp_nb, tp_nb, 'k', linestyle='dashed',\n","                 label=f'Naive Bayes (AUC = {auc(fp_nb, tp_nb):.4f})')\n","\n","    if random_forest != None:\n","        probas_rf = random_forest.predict_proba(X)[:, 1]\n","        fp_rf, tp_rf, _ = roc_curve(y, probas_rf)\n","        plt.plot(fp_rf, tp_rf, 'k', linestyle='dashdot',\n","                 label=f'Random Forest (AUC = {auc(fp_rf, tp_rf):.4f})')\n","\n","    if xgboost != None:\n","        probas_xgb = xgboost.predict_proba(X)[:, 1]\n","        fp_xgb, tp_xgb, _ = roc_curve(y, probas_xgb)\n","        plt.plot(fp_xgb, tp_xgb, 'k',\n","                 label=f'XGBoost (AUC = {auc(fp_xgb, tp_xgb):.4f})')\n","\n","    if lightgbm != None:\n","        probas_lgbm = lightgbm.predict_proba(X)[:, 1]\n","        fp_lgbm, tp_lgbm, _ = roc_curve(y, probas_lgbm)\n","        plt.plot(fp_lgbm, tp_lgbm, 'k', linestyle='dashed',\n","                 label=f'LightGBM (AUC = {auc(fp_lgbm, tp_lgbm):.4f})')\n","\n","    plt.plot(np.linspace(0, 1, 100),\n","             np.linspace(0, 1, 100),\n","             label='Baseline',\n","             linestyle='dotted',\n","             color='gray')\n","    plt.xlabel('False Positives')\n","    plt.ylabel('True Positives')\n","    plt.grid(True)\n","    plt.legend()\n","    plt.show()\n","\n","#######################################################################################\n","\n","def pred_cruzada(df, model, list_drop, label, enc, norm):\n","\n","    # Filtro para os anos de sobrevida de interesse\n","    df_sobrevida = df[~((df.obito_geral == 0) & (df[label] == 0))].reset_index(drop=True)\n","\n","    # Saída\n","    y = df_sobrevida[label].values\n","\n","    # Entradas\n","    X = df_sobrevida.drop(columns=list_drop)\n","    X_pp = test_preprocessing(X, enc, norm)\n","\n","    # Matriz de confusão\n","    plot_confusion_matrix(model, X_pp, y)"]}]}